{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Processing for Forecast Lab\n",
    "\n",
    "The purpose of this notebook is to do the time-consuming steps in the background as to not disrupt the flow of the lab.\n",
    "\n",
    "**Inputs needed:**\n",
    "\n",
    "**Bucket Name** - A name for an S3 bucket generated by the CloudFormation template.\n",
    "\n",
    "**Region** - Default is us-east-1, but available to change it here.\n",
    "\n",
    "**Project** - Name of the background project, as to not conflict with main Lab exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"forecastdemo-firstname-lastname\"\n",
    "region = \"us-east-1\"\n",
    "project = 'bp_forecastdemo_bg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "\n",
    "df = pd.read_csv(\"item-demand-time.csv\", dtype = object, names=['timestamp','value','item'])\n",
    "df.head(3)\n",
    "\n",
    "jan_to_oct = df[(df['timestamp'] >= '2014-01-01') & (df['timestamp'] <= '2014-10-31')]\n",
    "\n",
    "df = pd.read_csv(\"item-demand-time.csv\", dtype = object, names=['timestamp','value','item'])\n",
    "remaining_df = df[(df['timestamp'] >= '2014-10-31') & (df['timestamp'] <= '2014-12-01')]\n",
    "\n",
    "jan_to_oct.to_csv(\"item-demand-time-train.csv\", header=False, index=False)\n",
    "remaining_df.to_csv(\"item-demand-time-validation.csv\", header=False, index=False)\n",
    "\n",
    "key=\"elec_data/item-demand-time-train.csv\"\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(key).upload_file(\"item-demand-time-train.csv\")\n",
    "\n",
    "DATASET_FREQUENCY = \"H\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "\n",
    "datasetName= project+'_ds'\n",
    "datasetGroupName= project +'_dsg'\n",
    "s3DataPath = \"s3://\"+bucket_name+\"/\"+key\n",
    "\n",
    "create_dataset_group_response = forecast.create_dataset_group(DatasetGroupName=datasetGroupName,\n",
    "                                                              Domain=\"CUSTOM\",\n",
    "                                                             )\n",
    "datasetGroupArn = create_dataset_group_response['DatasetGroupArn']\n",
    "\n",
    "forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)\n",
    "\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName=datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = schema\n",
    ")\n",
    "\n",
    "datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=datasetArn)\n",
    "\n",
    "forecast.update_dataset_group(DatasetGroupArn=datasetGroupArn, DatasetArns=[datasetArn])\n",
    "\n",
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"ForecastRoleDemo\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"forecast.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_role_response = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "    )\n",
    "    role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "except iam.exceptions.EntityAlreadyExistsException:\n",
    "    print(\"The role \" + role_name + \" exists, ignore to create it\")\n",
    "    role_arn = boto3.resource('iam').Role(role_name).arn\n",
    "    \n",
    "policy_arn = \"arn:aws:iam::aws:policy/AmazonForecastFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "print(role_arn)\n",
    "\n",
    "datasetImportJobName = 'EP_DSIMPORT_JOB_TARGET'\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )\n",
    "\n",
    "ds_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_import_job_arn)\n",
    "\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = forecast.describe_dataset_import_job(\n",
    "        DatasetImportJobArn = ds_import_job_arn\n",
    "    )\n",
    "    \n",
    "    status = describe_dataset_import_job_response[\"Status\"]\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)\n",
    "\n",
    "project_bg = project\n",
    "datasetGroupArn_bg = datasetGroupArn\n",
    "datasetArn_bg = datasetArn\n",
    "role_name_bg = role_name\n",
    "key_bg = key\n",
    "bucket_name_bg = bucket_name\n",
    "region_bg = region\n",
    "ds_import_job_arn_bg = ds_import_job_arn\n",
    "\n",
    "%store project_bg\n",
    "%store datasetGroupArn_bg\n",
    "%store datasetArn_bg\n",
    "%store role_name_bg\n",
    "%store key_bg\n",
    "%store bucket_name_bg\n",
    "%store region_bg\n",
    "%store ds_import_job_arn_bg\n",
    "\n",
    "predictorName= project+'_deeparp_algo'\n",
    "forecastHorizon = 24\n",
    "algorithmArn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus'\n",
    "\n",
    "create_predictor_response=forecast.create_predictor(PredictorName=predictorName, \n",
    "                                                  AlgorithmArn=algorithmArn,\n",
    "                                                  ForecastHorizon=forecastHorizon,\n",
    "                                                  PerformAutoML= False,\n",
    "                                                  PerformHPO=False,\n",
    "                                                  EvaluationParameters= {\"NumberOfBacktestWindows\": 1, \n",
    "                                                                         \"BackTestWindowOffset\": 24}, \n",
    "                                                  InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn},\n",
    "                                                  FeaturizationConfig= {\"ForecastFrequency\": \"H\", \n",
    "                                                                        \"Featurizations\": \n",
    "                                                                        [\n",
    "                                                                          {\"AttributeName\": \"target_value\", \n",
    "                                                                           \"FeaturizationPipeline\": \n",
    "                                                                            [\n",
    "                                                                              {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                               \"FeaturizationMethodParameters\": \n",
    "                                                                                {\"frontfill\": \"none\", \n",
    "                                                                                 \"middlefill\": \"zero\", \n",
    "                                                                                 \"backfill\": \"zero\"}\n",
    "                                                                              }\n",
    "                                                                            ]\n",
    "                                                                          }\n",
    "                                                                        ]\n",
    "                                                                       }\n",
    "                                                 )\n",
    "\n",
    "predictor_arn = create_predictor_response['PredictorArn']\n",
    "\n",
    "timer = 0\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "    describe_predictor_version_response = forecast.describe_predictor(PredictorArn = predictor_arn)\n",
    "    status = describe_predictor_version_response[\"Status\"]\n",
    "    print(\"PredictorVersion: {}, time take: {} min\".format(status, timer))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "    timer += 1\n",
    "    time.sleep(60)\n",
    "\n",
    "predictor_arn_bg = predictor_arn\n",
    "%store predictor_arn_bg\n",
    "\n",
    "forecast.get_accuracy_metrics(PredictorArn=predictor_arn)\n",
    "\n",
    "forecastName= project+'_deeparp_algo_forecast'\n",
    "\n",
    "create_forecast_response=forecast.create_forecast(ForecastName=forecastName,\n",
    "                                                  PredictorArn=predictor_arn)\n",
    "forecast_arn = create_forecast_response['ForecastArn']\n",
    "\n",
    "timer = 0\n",
    "status = None\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "\n",
    "while time.time() < max_time:\n",
    "    describe_forecast_response = forecast.describe_forecast(ForecastArn=forecast_arn)\n",
    "    status = describe_forecast_response[\"Status\"]\n",
    "    print(\"Forecast: {}, time take: {} min\".format(status, timer))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    timer += 1\n",
    "    time.sleep(60)\n",
    "\n",
    "forecast_arn_bg = forecast_arn\n",
    "%store forecast_arn_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
